{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF and Linear Regression Demo\n",
    "https://www.oreilly.com/library/view/feature-engineering-for/9781491953235/ch04.html\n",
    "\n",
    "Proof of concept for one possible approach, using TF-IDF and ridge regression.\n",
    "\n",
    "This approach uses no engineered features, and exclusively bases the regression model on the presence or absence of certain words in the respondent's answer to a particular question.  We are not considering other responses, meaning this model is attempting to predict one trait from a single response.  In a final product, we would leverage all of the responses for determining traits.\n",
    "\n",
    "This notebook is for demonstrating the high-level concepts around converting text into features which can be used for using regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import Ridge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open_ended_1</th>\n",
       "      <th>E_Scale_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I would change my vacation week, because I am ...</td>\n",
       "      <td>2.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I would talk to my colleague and see if they w...</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I would feel upset because perhaps I already b...</td>\n",
       "      <td>2.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        open_ended_1  E_Scale_score\n",
       "0  I would change my vacation week, because I am ...       2.250000\n",
       "1  I would talk to my colleague and see if they w...       4.666667\n",
       "2  I would feel upset because perhaps I already b...       2.250000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the data to a df\n",
    "train = pd.read_csv('data/siop_ml_train_participant.csv')\n",
    "\n",
    "# Limit the results to a single answer / score combination for demonstration\n",
    "train = train.drop(['Respondent_ID', 'open_ended_2', 'open_ended_3', 'open_ended_4', 'open_ended_5', \n",
    "         'A_Scale_score', 'O_Scale_score', 'C_Scale_score', 'N_Scale_score'], axis=1)\n",
    "\n",
    "# Confirm that the data has been imported and is formatted correctly\n",
    "train.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_prep (df, column):\n",
    "    # Lowercase it all\n",
    "    df[column].str.lower()\n",
    "    \n",
    "    # Remove non-alphanumeric characters\n",
    "    df[column].replace('[^a-zA-Z0-9]', ' ', regex = True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "prepped_data = simple_prep (train, 'open_ended_1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 709)\t0.08148980333334543\n",
      "  (0, 103)\t0.06611098222547579\n",
      "  (0, 390)\t0.08877500133530604\n",
      "  (0, 660)\t0.05553590665538873\n",
      "  (0, 677)\t0.07857420551439168\n",
      "  (0, 70)\t0.3604897556594089\n",
      "  (0, 33)\t0.1305087284129816\n",
      "  (0, 77)\t0.16820201970082257\n",
      "  (0, 198)\t0.33640403940164515\n",
      "  (0, 604)\t0.14556477338940635\n",
      "  (0, 290)\t0.13271746418775518\n",
      "  (0, 427)\t0.19711231983512112\n",
      "  (0, 547)\t0.16301025719261872\n",
      "  (0, 675)\t0.11523712986393006\n",
      "  (0, 94)\t0.11749466492809\n",
      "  (0, 84)\t0.13627928011202659\n",
      "  (0, 69)\t0.0658285866062222\n",
      "  (0, 414)\t0.10035942659721815\n",
      "  (0, 700)\t0.198079804788346\n",
      "  (0, 59)\t0.22437438100114485\n",
      "  (0, 606)\t0.15019760255331036\n",
      "  (0, 529)\t0.1371160903087401\n",
      "  (0, 626)\t0.07985488931482768\n",
      "  (0, 610)\t0.10189821294052104\n",
      "  (0, 430)\t0.25094145262797446\n",
      "  (0, 447)\t0.18669882033089774\n",
      "  (0, 413)\t0.1674868586227046\n",
      "  (0, 433)\t0.15365722436421728\n",
      "  (0, 29)\t0.11380033428729315\n",
      "  (0, 208)\t0.18525331498842948\n",
      "  (0, 83)\t0.12774260271556143\n",
      "  (0, 411)\t0.21574941798242342\n",
      "  (0, 338)\t0.21280384721175782\n",
      "  (0, 437)\t0.24035437943508617\n",
      "  (0, 373)\t0.0934495298598548\n"
     ]
    }
   ],
   "source": [
    "def vectorize_training_data (df, column):\n",
    "    # Set the TF-IDF vectorization settings\n",
    "    vectorizer = TfidfVectorizer(min_df=5)\n",
    "    \n",
    "    # Convert text into vectors\n",
    "    X = vectorizer.fit_transform(df[column]) \n",
    "    \n",
    "    # return the vectorizer object so we can use it later for evaluation\n",
    "    return X, vectorizer\n",
    "    \n",
    "X, vectorizer = vectorize_training_data (prepped_data, 'open_ended_1')\n",
    "\n",
    "print(X[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=241, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Utilizing ridge regression for this PoC\n",
    "mod = Ridge(alpha=1.0, random_state=241)\n",
    "\n",
    "# Set the criterion column so we can fit the model\n",
    "y = train['E_Scale_score']\n",
    "\n",
    "# Fit the model using the our training data and criterion column\n",
    "mod.fit(X, y) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Viewing Sample Results\n",
    "\n",
    "Typically the accuracy of a model would be assessed by utilizing hold-out groups and training on x% of the data, then testing on the remaining portion.  Multiple 'folds' of this evaluation can be performed by randomly assigning the data to be in training or testing set.  This multiple folding process is known as Cross-Validation.\n",
    "\n",
    "For this model we are simply proofing the idea, and so we are assessing the accuracy of the model by looking at a random sample row and using the model to classify the test row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_results (row_num, vectorizer):\n",
    "    print ('User input for row [{0}]: {1}\\n'.format(row_num, train['open_ended_1'][row_num]))\n",
    "    print ('Actual Score: \\t\\t{0}'.format(train['E_Scale_score'][row_num].round(2)))\n",
    "    \n",
    "    # Use the same data transformation process on the sample row provided\n",
    "    sample_test_data = vectorizer.transform([train['open_ended_1'][row_num]]) \n",
    "    \n",
    "    # Run that transformed vector against the model by using .predict()\n",
    "    rslt = mod.predict(sample_test_data)\n",
    "    \n",
    "    print ('Predicted Score: \\t{0}'.format(rslt[0].round(2)))\n",
    "    print ('\\nCriterion StdDev: \\t{0}'.format(train['E_Scale_score'].std().round(2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When hosted in GitHub, this sample will only show the most recent run, however you can clone this repository to run it locally and sample the results yourself.  The results for this model are not great, but better than guessing.  Standard deviation is provided for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User input for row [514]: I would tell my co-worker if we can't decide between the two of us we need to find another solution. Flipping a coin is fair. Heads, I get the week off. Tails, you get the week off. If the co-worker wasn't agreeing to this, I would just give them the week off and make them look bad for not being fair.\n",
      "\n",
      "Actual Score: \t\t4.5\n",
      "Predicted Score: \t4.03\n",
      "\n",
      "Criterion StdDev: \t0.79\n"
     ]
    }
   ],
   "source": [
    "# To see results for a specific row, change this value to a row index\n",
    "test_row_index = random.randint(0, len(train['open_ended_1']))\n",
    "\n",
    "sample_results (test_row_index, vectorizer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
