{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixed Weighted Model\n",
    "\n",
    "This approach will use a regression model for each input item, and then weight the outputs of these models based on their scored criterion relevance from SME's.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Respondent_ID</th>\n",
       "      <th>open_ended_1</th>\n",
       "      <th>open_ended_2</th>\n",
       "      <th>open_ended_3</th>\n",
       "      <th>open_ended_4</th>\n",
       "      <th>open_ended_5</th>\n",
       "      <th>E_Scale_score</th>\n",
       "      <th>A_Scale_score</th>\n",
       "      <th>O_Scale_score</th>\n",
       "      <th>C_Scale_score</th>\n",
       "      <th>N_Scale_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10446116527</td>\n",
       "      <td>I would change my vacation week, because I am ...</td>\n",
       "      <td>I would reach out to my boss and ask him or he...</td>\n",
       "      <td>I would not go. I am a not a social person. I ...</td>\n",
       "      <td>I would ask my manager why he/she gave me such...</td>\n",
       "      <td>I would find this experience super enjoyable. ...</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>2.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10440100535</td>\n",
       "      <td>I would talk to my colleague and see if they w...</td>\n",
       "      <td>I would continue to work on the project that w...</td>\n",
       "      <td>I would talk to my colleague and try to talk t...</td>\n",
       "      <td>I would feel upset about the negative feedback...</td>\n",
       "      <td>I would find this experience enjoyable. I feel...</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.416667</td>\n",
       "      <td>4.583333</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10462850071</td>\n",
       "      <td>I would feel upset because perhaps I already b...</td>\n",
       "      <td>I would start working on the project now and g...</td>\n",
       "      <td>I would feel guilty about thinking about not g...</td>\n",
       "      <td>I would feel really defensive about it. I woul...</td>\n",
       "      <td>I would find it enjoyable because I would be r...</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>4.083333</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>2.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Respondent_ID                                       open_ended_1  \\\n",
       "0    10446116527  I would change my vacation week, because I am ...   \n",
       "1    10440100535  I would talk to my colleague and see if they w...   \n",
       "2    10462850071  I would feel upset because perhaps I already b...   \n",
       "\n",
       "                                        open_ended_2  \\\n",
       "0  I would reach out to my boss and ask him or he...   \n",
       "1  I would continue to work on the project that w...   \n",
       "2  I would start working on the project now and g...   \n",
       "\n",
       "                                        open_ended_3  \\\n",
       "0  I would not go. I am a not a social person. I ...   \n",
       "1  I would talk to my colleague and try to talk t...   \n",
       "2  I would feel guilty about thinking about not g...   \n",
       "\n",
       "                                        open_ended_4  \\\n",
       "0  I would ask my manager why he/she gave me such...   \n",
       "1  I would feel upset about the negative feedback...   \n",
       "2  I would feel really defensive about it. I woul...   \n",
       "\n",
       "                                        open_ended_5  E_Scale_score  \\\n",
       "0  I would find this experience super enjoyable. ...       2.250000   \n",
       "1  I would find this experience enjoyable. I feel...       4.666667   \n",
       "2  I would find it enjoyable because I would be r...       2.250000   \n",
       "\n",
       "   A_Scale_score  O_Scale_score  C_Scale_score  N_Scale_score  \n",
       "0       3.750000       3.166667       3.750000       2.916667  \n",
       "1       4.416667       4.583333       5.000000       1.333333  \n",
       "2       4.750000       4.083333       4.666667       2.166667  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the data to a df\n",
    "df = pd.read_csv('data/siop_ml_train_participant.csv')\n",
    "\n",
    "# Import the test data to a new df\n",
    "eval_df = pd.read_csv('data/siop_ml_dev_participant.csv')\n",
    "\n",
    "# Import the weighting matrix\n",
    "weighting_matrix = pd.read_csv('data/weights/dummy_matrix.csv')\n",
    "\n",
    "# Confirm that the data has been imported and is formatted correctly\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For clarity and simplicity, the training and criterion columns are declared in these hardcoded variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_columns = ['open_ended_1', 'open_ended_2', 'open_ended_3', 'open_ended_4', 'open_ended_5']\n",
    "criterion_columns = ['E_Scale_score', 'A_Scale_score', 'O_Scale_score', 'C_Scale_score', 'N_Scale_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_prep (df):\n",
    "    for col in training_columns:\n",
    "        \n",
    "        # Lowercase it all\n",
    "        df[col].str.lower()\n",
    "    \n",
    "        # Remove non-alphanumeric characters\n",
    "        df[col].replace('[^a-zA-Z0-9]', ' ', regex = True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "prepped_data = simple_prep (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate our testing and training sets and show their relative sizes\n",
    "train, test = train_test_split(prepped_data, test_size=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation and Training\n",
    "\n",
    "First we'll need to defind the function for vectorizing each input column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abstract away as much as possible so we can reuse this general vectorizing and training function\n",
    "def vectorize_and_train (df_train, y_train):\n",
    "    # Set the TF-IDF vectorization settings\n",
    "    vectorizer = TfidfVectorizer(min_df=1, ngram_range=(1,3))\n",
    "    \n",
    "    # Convert text into vectors\n",
    "    X_train = vectorizer.fit_transform(df_train) \n",
    "    \n",
    "    # We're using the same y-values from the training df\n",
    "    y_train = y_train\n",
    "    \n",
    "    # Generate a new model instance\n",
    "    mod = new_model()\n",
    "    \n",
    "    # Fit our model with the data\n",
    "    mod.fit(X_train, y_train)\n",
    "    \n",
    "    # return the vectorizer object so we can use it later for evaluation\n",
    "    return X_train, y_train, vectorizer, mod\n",
    "\n",
    "# Allow a new model to be initialized for each column / regressor\n",
    "def new_model ():\n",
    "    # Define the model parameters we'll be using\n",
    "    mod = Ridge(alpha=1.0, random_state=42)\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our model sets\n",
    "X_training_set = {}    \n",
    "y_training_set = {}\n",
    "vectorizer_set = {}\n",
    "model_set = {}\n",
    "\n",
    "# Iterate over the training columns\n",
    "for training_col in training_columns:\n",
    "    \n",
    "    # Generate a new dict for each column so we can access the models later\n",
    "    X_training_set[training_col] = {}\n",
    "    y_training_set[training_col] = {}\n",
    "    vectorizer_set[training_col] = {}\n",
    "    model_set[training_col] = {}\n",
    "    \n",
    "    # Within the training columns, iterate over the outcome variables\n",
    "    for criterion_col in criterion_columns:    \n",
    "        X_training_set[training_col][criterion_col], y_training_set[training_col][criterion_col], vectorizer_set[training_col][criterion_col], model_set[training_col][criterion_col] = vectorize_and_train (train[training_col], train[criterion_col])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming and Predicting on Input Data\n",
    "\n",
    "Since we've assessed that the model works and is make acceptable predictions, we can move ahead and process the input file we received at the beginning of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For each of the columns in the evaluation file, we \n",
    "\n",
    "# DEV NOTE iterate over the evaluation columns afterwards\n",
    "# FOR NOW, just just evaluate a single column, open_ended_1\n",
    "#for eval_col in assessment_df:\n",
    "sj_column = 'open_ended_1'\n",
    "ec_column = 'E_Scale_score'\n",
    "\n",
    "# For each of the outcome variables, predict a value from this input column\n",
    "# for ec_column in criterion_columns:\n",
    "\n",
    "# Transform the evaluation data into vectorized data on the correct vectorizer vocab\n",
    "eval_transformed = vectorizer_set[sj_column][ec_column].transform(eval_df[sj_column])\n",
    "\n",
    "# Predict the values with the corresponding model\n",
    "y_pred = model_set[sj_column][ec_column].predict(eval_transformed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a Dataframe from the results\n",
    "output = pd.DataFrame(data={\n",
    "    \"Respondent_ID\":eval_df[\"Respondent_ID\"],\n",
    "    \"Prediction\":y_pred\n",
    "    })\n",
    "\n",
    "# Ensure the output is the form of a question.  \"What is...\"\n",
    "output = output[[\"Respondent_ID\", \"Prediction\"]]\n",
    "\n",
    "# Send the output frame to a CSV, and exclude the indices with index=False\n",
    "output.to_csv('data/wtf_are_we_doing.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Testing and Evaluation\n",
    "\n",
    "Now that we've got our models trained, we'll want to evaluate their performance on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JK JK, I'm not actually doing that right now :sadpanda:\n",
    "\n",
    "# If you want to modify this section to include test evaluation, this would be really helpful"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
