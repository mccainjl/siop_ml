{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting from Multiple Inputs\n",
    "\n",
    "As we explore more options around encoded values, it'll be helpful to include more predictors and engineered features.  In order to do this, we'll need to be able to encode features and then factor them into models.  This notebook works through these examples with a sample encoding function and can be used as a reference for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Respondent_ID</th>\n",
       "      <th>open_ended_1</th>\n",
       "      <th>open_ended_2</th>\n",
       "      <th>open_ended_3</th>\n",
       "      <th>open_ended_4</th>\n",
       "      <th>open_ended_5</th>\n",
       "      <th>E_Scale_score</th>\n",
       "      <th>A_Scale_score</th>\n",
       "      <th>O_Scale_score</th>\n",
       "      <th>C_Scale_score</th>\n",
       "      <th>N_Scale_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10446116527</td>\n",
       "      <td>I would change my vacation week, because I am ...</td>\n",
       "      <td>I would reach out to my boss and ask him or he...</td>\n",
       "      <td>I would not go. I am a not a social person. I ...</td>\n",
       "      <td>I would ask my manager why he/she gave me such...</td>\n",
       "      <td>I would find this experience super enjoyable. ...</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>2.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10440100535</td>\n",
       "      <td>I would talk to my colleague and see if they w...</td>\n",
       "      <td>I would continue to work on the project that w...</td>\n",
       "      <td>I would talk to my colleague and try to talk t...</td>\n",
       "      <td>I would feel upset about the negative feedback...</td>\n",
       "      <td>I would find this experience enjoyable. I feel...</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.416667</td>\n",
       "      <td>4.583333</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10462850071</td>\n",
       "      <td>I would feel upset because perhaps I already b...</td>\n",
       "      <td>I would start working on the project now and g...</td>\n",
       "      <td>I would feel guilty about thinking about not g...</td>\n",
       "      <td>I would feel really defensive about it. I woul...</td>\n",
       "      <td>I would find it enjoyable because I would be r...</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>4.083333</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>2.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Respondent_ID                                       open_ended_1  \\\n",
       "0    10446116527  I would change my vacation week, because I am ...   \n",
       "1    10440100535  I would talk to my colleague and see if they w...   \n",
       "2    10462850071  I would feel upset because perhaps I already b...   \n",
       "\n",
       "                                        open_ended_2  \\\n",
       "0  I would reach out to my boss and ask him or he...   \n",
       "1  I would continue to work on the project that w...   \n",
       "2  I would start working on the project now and g...   \n",
       "\n",
       "                                        open_ended_3  \\\n",
       "0  I would not go. I am a not a social person. I ...   \n",
       "1  I would talk to my colleague and try to talk t...   \n",
       "2  I would feel guilty about thinking about not g...   \n",
       "\n",
       "                                        open_ended_4  \\\n",
       "0  I would ask my manager why he/she gave me such...   \n",
       "1  I would feel upset about the negative feedback...   \n",
       "2  I would feel really defensive about it. I woul...   \n",
       "\n",
       "                                        open_ended_5  E_Scale_score  \\\n",
       "0  I would find this experience super enjoyable. ...       2.250000   \n",
       "1  I would find this experience enjoyable. I feel...       4.666667   \n",
       "2  I would find it enjoyable because I would be r...       2.250000   \n",
       "\n",
       "   A_Scale_score  O_Scale_score  C_Scale_score  N_Scale_score  \n",
       "0       3.750000       3.166667       3.750000       2.916667  \n",
       "1       4.416667       4.583333       5.000000       1.333333  \n",
       "2       4.750000       4.083333       4.666667       2.166667  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the data to a df\n",
    "df = pd.read_csv('data/siop_ml_train_participant.csv')\n",
    "\n",
    "# Confirm that the data has been imported and is formatted correctly\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In most notebooks, this is where you'd separate your training data in order to evaluate model effectiveness.  Instead, we're just using the entire dataset and we'll be training on the entire input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1088, 12)\n",
      "Respondent_ID                                                  10440099152\n",
      "open_ended_1             I would find out what everyone's plans are. Th...\n",
      "open_ended_2             I would get this project done as quickly as po...\n",
      "open_ended_3             I would still attend the networking meeting. I...\n",
      "open_ended_4             I would discuss the feedback with my superviso...\n",
      "open_ended_5             I would absolutely jump at the opportunity to ...\n",
      "E_Scale_score                                                      3.16667\n",
      "A_Scale_score                                                      4.16667\n",
      "O_Scale_score                                                      3.91667\n",
      "C_Scale_score                                                      4.66667\n",
      "N_Scale_score                                                      1.91667\n",
      "extraversion_encoding                                                    1\n",
      "Name: 224, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# This step simply adds a dummy column, representing the addition of a new feature\n",
    "\n",
    "# We're adding a simple title here, however this is a dummy variable\n",
    "val_name = \"extraversion_encoding\"\n",
    "\n",
    "# We're creating a function that will encode a given value as either high or low\n",
    "def code_high_or_low (value):\n",
    "    # If our given value is over 3 (the average E score) they are 'high'\n",
    "    if value > 3:\n",
    "        coding = 1\n",
    "    # Otherwise, give them a 'low' encoding\n",
    "    else:\n",
    "        coding = 0\n",
    "    return coding\n",
    "\n",
    "# Using the .apply() function, we can take this user function and specify the 'E_Scale_score' \n",
    "# column for our function.  Then, assign the output of that function to a new column in our training dataframe\n",
    "train[val_name] = train.E_Scale_score.apply(code_high_or_low)\n",
    "\n",
    "# Let's check our shape here:\n",
    "print(train.shape)\n",
    "\n",
    "# Let's also view a specific, random respondent.  If they are \n",
    "print (train.iloc[np.random.randint(0, len(train))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell above should have a randomly selected participant (`train.iloc[np.random.randint(0, len(train))]`) - if their extraversion score is above 3, their `extraversion_encoding` should be 1, otherwise it should be 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1088,)\n",
      "(1088,)\n"
     ]
    }
   ],
   "source": [
    "# For simplicity, let's limit this to one input column, which we'll assign to df_train\n",
    "df_train = train['open_ended_1']\n",
    "\n",
    "# To understand where we'll be adding the extra feature column here we'll call it 'df_train_extra'\n",
    "df_train_extra = train['extraversion_encoding']\n",
    "\n",
    "# Our outcome variable should reflect the same item we chose to code for above\n",
    "y_train = train['E_Scale_score']\n",
    "\n",
    "# Check to make sure that the two of our shapes are equal:\n",
    "print(df_train.shape)\n",
    "print(df_train_extra.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we're using a ridge regression model\n",
    "mod = Ridge(alpha=1.0, random_state=42)\n",
    "\n",
    "# Set the TF-IDF vectorization settings\n",
    "vectorizer = TfidfVectorizer(min_df=1, max_df=4, ngram_range=(1,2))\n",
    "\n",
    "# Here we start by fitting our vectors to the text inputs\n",
    "main_transformer = vectorizer.fit_transform(df_train) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to combine the vectorized inputs, we'll need to make them a dense array. Other vectorizers support todense() as described in the Towards Data Science post linked below, however the TFIDF Vectorizer instead uses toarray().\n",
    "\n",
    "https://towardsdatascience.com/natural-language-processing-on-multiple-columns-in-python-554043e05308\n",
    "\n",
    "Below, we expect to see a dense matrix with many features (columns) but they should have the same number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1088, 16755)\n",
      "(1088,)\n"
     ]
    }
   ],
   "source": [
    "# Condense our sparse matrix into an array, and set the feature names as columns\n",
    "dense_transformer = pd.DataFrame(main_transformer.toarray(), columns=vectorizer.get_feature_names())\n",
    "\n",
    "# Since we're manipulating the columns a bunch, let's make sure we haven't buggered anything\n",
    "print (dense_transformer.shape)\n",
    "print (df_train_extra.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've got a dense array and dataframe column for the encoded values, we can combine them with the pandas concat function.  In order to make sure that we don't mix up our indices, we'll need to reset them here, otherwise the .shapes get out of whack.\n",
    "\n",
    "Lastly, we can transform the output with our fancy new combined dataframe, and train the regression model on that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=42, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the two dataframes\n",
    "X_train = pd.concat([dense_transformer.reset_index(), df_train_extra.reset_index()], axis=1)\n",
    "\n",
    "# Convert text into vectors\n",
    "X_test = vectorizer.transform(df_train) \n",
    "\n",
    "# We're using the same y-values from the training df\n",
    "y_train = y_train\n",
    "\n",
    "# # Fit our model with the data\n",
    "mod.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great.  Now the model is trained and we can make predictions with it.  Since we encoded all high extraversion values with a 1, this should give the model a strong weight for the value of this fictional 'extraversion value' we've generated.\n",
    "\n",
    "The snippet below takes a standard chunk of text, however the 'extraversion value' is randomized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual extraversion is 3.67\n",
      "Predicted extraversion is 3.72\n",
      "Respondent randomly assigned \"1\" as their E encoding\n",
      "\n",
      "Respondent Input: \n",
      "I would not give in either.  If I gave in, my colleague might think that I am weak and run over me in the future.  I would suggest that we either split up the days, or come to some sort of other compromise.\n"
     ]
    }
   ],
   "source": [
    "# Select a random participant\n",
    "respondent_id = np.random.randint(0, len(df))\n",
    "\n",
    "# Randomly generate a high or low encoding\n",
    "extraversion_encoding = np.random.randint(0, 2)\n",
    "\n",
    "# Set the respondent's true value for \n",
    "true_extraversion_value = y_train[respondent_id]\n",
    "\n",
    "# Select a random respondent's response for item #1\n",
    "example_text = df['open_ended_1'][respondent_id]\n",
    "\n",
    "# Create a new Dataframe so we can concatenate it for transformation later\n",
    "extra_value_for_test = pd.DataFrame(columns=['ext_coding'])\n",
    "\n",
    "# Assign the randomly generated value to the 0th row in the dataframe\n",
    "extra_value_for_test.loc[0] = extraversion_encoding\n",
    "\n",
    "# Transform the testing text and condense it\n",
    "main_transformer = vectorizer.transform([example_text]) \n",
    "dense_transformer = pd.DataFrame(main_transformer.toarray(), columns=vectorizer.get_feature_names())\n",
    "\n",
    "# Generate an example input by concatenating our text and encoded dataframes\n",
    "example_test = pd.concat([dense_transformer.reset_index(), extra_value_for_test.reset_index()], axis=1)\n",
    "\n",
    "# Generate the prediction for this example input\n",
    "prediction = mod.predict(example_test)\n",
    "\n",
    "print(\"Actual extraversion is {0}\".format(true_extraversion_value.round(2)))\n",
    "print(\"Predicted extraversion is {0}\\nRespondent randomly assigned \\\"{2}\\\" as their E encoding\".format(prediction[0].round(2), example_text, extraversion_encoding))\n",
    "print(\"\\nRespondent Input: \\n{0}\".format(example_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "If the example above is working correctly, you should generally see that the predicted value for extraversion is swayed by encoding for the `extraversion_encoding`. When this encoding is accurate, such as for cases where actual extraversion is high and their encoding is high as well, we should see that the prediction is closer.  \n",
    "\n",
    "If the extraversion is low and the encoding is still high however (or the reverse), then we should expect to see a greater distance between the predicted and actual values.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
