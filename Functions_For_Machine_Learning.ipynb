{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions For Coding Text Features\n",
    "\n",
    "Below is a list of functions we developed to code for features to be used as predictors in our ML model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import nltk\n",
    "import PyPDF2\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Past Tense Words\n",
    "\n",
    "The function below tags each text answer for the presence of past tense words as classified by the nltk package.  Past tense is one of the many indices used in classic LIWC studies (e.g., Pennebaker & Francis, 1996/1999), which have been shown to significantly predict personality traits.  We cannot use the LIWC library here as it is not open access, but we can approximate it using the nltk package.  This function returns the percentage of past tense words in each answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pastTag(user_input):\n",
    "    past = 0\n",
    "    words = user_input.split()\n",
    "    for word in nltk.pos_tag(words):\n",
    "        if (word[1] == \"VBD\") or (word[1] == \"VBN\"):\n",
    "            past += 1\n",
    "        percentpast = past/len(words)\n",
    "    return percentpast  \n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Present Tense Words\n",
    "\n",
    "The presentTag() function tags each text answer for the presence (0) or absence (1) of present tense words as classified by the nltk package.  Is is also an approximation to the LIWC measure of present tense.  Fewer present tense words have been found to be predictive of openness to experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def presentTag(user_input):\n",
    "    present = 0\n",
    "     \n",
    "    words = user_input.split()\n",
    "    for word in nltk.pos_tag(words):\n",
    "        if (word[1] == \"VBG\") or (word[1] == \"VBP\") or (word[1] == \"VPZ\"):\n",
    "            present += 1\n",
    "    percentpresent = present/len(words)\n",
    "    return percentpresent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Articles\n",
    "\n",
    "The use of fewer articles (i.e., \"a\" or \"the\") has been found to positively predict agreeableness.  The following function caculates the percentage of articles in each text answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def articleTag(user_input):\n",
    "    \n",
    "    articles = 0\n",
    "    words = user_input.split()\n",
    "    for word in words:\n",
    "        if (word == \"a\") or (word == \"the\") or (word == \"A\") or (word == \"The\"):\n",
    "            articles += 1\n",
    "\n",
    "    percentarticles = articles/len(words)\n",
    "    return percentarticles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Person Singular\n",
    "\n",
    "The use of more first person singular pronouns (i.e., \"I\", \"me\", \"my\" or \"mine\") has been shown to positively predict neuroticism and negatively predict openness to experience.  The following function calculates the percentage of first person singular pronouns used in each text answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def firstpersonTag(user_input):\n",
    "    firstperson = 0\n",
    "    words = user_input.split()\n",
    "    for word in words:\n",
    "        if (word == \"I\") or (word == \"me\") or (word == \"my\") or (word == \"mine\") or (word == \"Me\") or  (word == \"My\") or (word == \"Mine\"):\n",
    "            firstperson += 1\n",
    "        \n",
    "    percentfirst = firstperson/len(words)\n",
    "    return percentfirst\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Length\n",
    "\n",
    "The wordLengths function measures the average word length of each text answer and then returns the percentage of words that have five or more letters.  Having a higher percentage of words greater than five letters long has been found to be a good predictor of openness to experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordLengths(user_input):\n",
    "  \n",
    "    words = list(map(len,user_input.split()))\n",
    "    sumlengths = sum(i > 5 for i in words)\n",
    "    percentoverfive = sumlengths/len(words)\n",
    "    return percentoverfive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative Affect Words\n",
    "\n",
    "Negative affect is another index known to predict traits such as neuroticism (positively) and extraversion, agreeableness, and conscientiousness (negatively). We chose to use a publicly available libraries from Loughran-McDonald available here: https://sraf.nd.edu/textual-analysis/resources/#LM%20Sentiment%20Word%20Lists or here https://github.com/lcdm-uiuc/ml-finance.  The following syntax reads in the word list from a downloaded pdf and converts it into a vector that can be used to tag the text answers for the presence of negative words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('LM_Negative.pdf', 'rb')\n",
    "\n",
    "# creating a pdf reader object\n",
    "fileReader = PyPDF2.PdfFileReader(file)\n",
    "pageObj = fileReader.getPage(0)\n",
    "page_content = pageObj.extractText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "negativewords = \"\"\n",
    "for page in range(fileReader.numPages):\n",
    "    pageObj = fileReader.getPage(page)\n",
    "    page_content = pageObj.extractText()\n",
    "    negativewords = negativewords + page_content\n",
    "negwords = negativewords.split()\n",
    "\n",
    "negwords = negwords[7:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function takes the list of words imported above (ie., \"negwords\") and tags each text answer as to the percentage of negative words present in its text.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negAffect(user_input):\n",
    "    negative = 0\n",
    "    words = user_input.split()\n",
    "    for word in words:\n",
    "        if word.upper() in negwords:\n",
    "            negative = negative + 1\n",
    "\n",
    "    percentnegative = negative/len(words)\n",
    "    return percentnegative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positive Affect Words\n",
    "\n",
    "We also used the Loughran-McDonald sentiment word list again (this time from https://github.com/lcdm-uiuc/ml-finance) to code for positive words.  Percentage of positive words has been found to positively predict extraversion, conscientiousness, and agreeableness and to negatively predict neuroticism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('LM_Positive.pdf', 'rb')\n",
    "\n",
    "# creating a pdf reader object\n",
    "fileReader = PyPDF2.PdfFileReader(file)\n",
    "pageObj = fileReader.getPage(0)\n",
    "page_content = pageObj.extractText()\n",
    "#print(page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "positivewords = \"\"\n",
    "for page in range(fileReader.numPages):\n",
    "    pageObj = fileReader.getPage(page)\n",
    "    page_content = pageObj.extractText()\n",
    "    positivewords = positivewords + page_content\n",
    "#print(negativewords)\n",
    "poswords = positivewords.split()\n",
    "\n",
    "poswords = poswords[7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posAffect(user_input):\n",
    "    positive = 0\n",
    "    words = user_input.split()\n",
    "    for word in words:\n",
    "        if word.upper() in poswords:\n",
    "            positive = positive + 1\n",
    "        \n",
    "    percentpositive = positive/len(words)\n",
    "    return percentpositive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tentative Words\n",
    "\n",
    "The use of tentative words that lessen certainty about a statement (e.g., \"may\", \"possibly\", \"seems to\") has been found to positively predict openness to experience and negatively predict extraversion.  We created a quick and dirty library of tentative words by looking online (mainly here: https://lo.unisa.edu.au/pluginfile.php/499128/mod_resource/content/2/Tentative%20language%20Nov%202015.pdf) to calculate the percentage of tentative words in each text answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tentwords = [\"may\", \"might\", \"can\", \"could\", \"possibly\", \"probably\", \"likely\", \"possible\", \"unlikely\", \"probable\", \"tends\", \"appears\", \"suggests\", \"seems\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tentAffect(user_input):\n",
    "    tentative = 0\n",
    "    words = user_input.split()\n",
    "    for word in words:\n",
    "        if word.upper() in tentwords:\n",
    "            tentative = tentative + 1\n",
    "            print\n",
    "       \n",
    "    percenttentative = tentative/len(words)\n",
    "    return percenttentative\n",
    "\n",
    "tentAffect(\"I may go\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causal Words\n",
    "\n",
    "Although more complicated text mining is usually needed to fully detect causal speech, we used a crude list of causal words from this publication (https://www.aaai.org/Papers/FLAIRS/2002/FLAIRS02-071.pdf) to do a quick tagging of causal speech as well.  Decreased use of causal words is usually positively associated with extraversion, conscientiousness, and openness to experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "causewords = [\"induce\", \"produce\", \"generate\", \"effect\", \"affect\", \"bring\", \"arouse\", \"provoke\", \"elicit\", \"lead\", \"trigger\", \n",
    "             \"derive\", \"associate\", \"relate\", \"link\", \"stem\", \"originate\", \"result\", \"stir\", \"entail\", \"contribute\", \"set\", \"commence\",\n",
    "             \"conduce\", \"educe\", \"spark\", \"evoke\", \"implicate\", \"activate\", \"actuate\", \"kindle\", \"fire\", \"stimulate\", \"call\", \"unleash\",\n",
    "             \"effectuate\", \"kick\", \"give\", \"birth\", \"call\", \"put\", \"create\", \"launch\", \"develop\", \"start\", \"make\", \"begin\", \"rise\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def causeAffect(user_input):\n",
    "    causal = 0\n",
    "    words = user_input.split()\n",
    "    for word in words:\n",
    "        if word.upper() in causewords:\n",
    "            causal = causal + 1\n",
    "        \n",
    "    percentcausal = causal/len(words)\n",
    "    return percentcausal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
